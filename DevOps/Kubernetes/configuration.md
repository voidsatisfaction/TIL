# configuration

- 의문
- 팟 및 컨테이너 리소스 관리
  - CPU
  - Memory
- 리소스 요청이 포함된 팟을 스케줄링하는 방법
- 쿠버네티스가 리소스 요청 및 제한을 적용하는 방법
  - CPU
  - Memory

## 의문

## 파드 및 컨테이너 리소스 관리

### CPU

- 개요
  - 1CPU 단위는 노드가 물리 호스트인지 아니면 물리 호스트 내에서 실행되는 가상 머신인지에 따라 1물리 CPU 코어 또는 1 가상 코어에 해당함
  - e.g) `0.5`로 설정하는 경우, `1.0`CPU를 요청했을 때와 비교하여 절반의 CPU타임을 요청한다는 의미(500밀리코어)

### Memory

- 개요
  - 바이트 단위로 측정함
    - `400m`
      - 0.4바이트 요청
    - `400Mi`
      - 400 메비바이트
    - `400M`
      - 400 메가바이트

## 리소스 요청이 포함된 팟을 스케줄링하는 방법

- 개요
  - 팟을 생성할 때, 쿠버네티스 스케줄러는 팟을 실행할 노드를 선택
  - 스케줄러는 각 리소스 타입마다 스케줄된 컨테이너의 리소스 요청 합계가 노드 용량보다 작도록 함

## 쿠버네티스가 리소스 요청 및 제한을 적용하는 방법

- kubelet이 팟의 컨테이너를 시작할 때, 해당 컨테이너의 메모리/CPU 요청 및 제한을 컨테이너 런타임에 전달
- cgroup을 설정하고, 명시적 제한을 적용

### CPU

- CPU limit
  - 컨테이너가 사용할 수 있는 CPU 시간에 대한 강한 상한을 정의하여, CPU 스케줄링 간격(time slice)마다 리눅스 커널이 이 제한이 초과되었는지 확인하고, 초과되었다면 cgroup의 실행 재개를 허가하지 않고 기다림(throttling)
  - 구현
    - cgroup cpu.cfs_period_us, cpu.cfs_quota_us(마이크로세컨트 - 비슷하게 생긴 u로 사용하는 듯) (cfs bandwidth control)

![](./images/configuration/cpu_time_definition1.png)

- CPU request
  - 가중치 설정을 정의
    - CPU부하가 높은 시스템에서 여러개의 컨테이너가 실행되어야 하는 경우, CPU요청량에 비례해서 남은 CPU 자원을 비율로 분배받는다
      - e.g) 2000m vs 1000m을 cpu request로 설정하였다면, 남은 자원을 사용할 필요가 있는 경우 2:1로 분배함
  - 구현
    - cgroup cpu.shares(즉, CPU time)
      - 생각해보면, cpu time정의로 설정해도 ok인 것이, 어차피 scheduler가 node의 실제 코어를 넘는 cpu이상으로 scheduling을 안할것이기 때문에, 최소로 각 팟이 설정한 expected한 cpu time 이상을 보장받을 수 있다

### Memory

- memory request
  - 주로 팟 스케줄링 과정에서 사용됨
- memory limit
  - cgroup에 대한 메모리 사용량 상한을 정의
    - 컨테이너 제한보다 더 많은 메모리를 할당받으려고 하면, 리눅스 커널의 OOM이 활성화되고, 할당 받으려고 했던 컨테이너의 프로세스 중 하나를 종료
    - 해당 프로세스의 PID가 1이고, 컨테이너가 재시작 가능으로 표시되어 있다면, 쿠버네티스가 해당 컨테이너를 재시작 함
  - 메모리 기반 볼륨(`emptyDir`)의 페이지에도 적용될 수 있음
  - 주의
    - 한 컨테이너가 메모리 요청을 초과하고, 해당 노드의 메모리가 부족해지면, 해당 컨테이너가 속한 팟이 축출될 수 있음
