# 웹 개발자를 위한 대규모 서비스를 지탱하는 기술

- 의문
- Ch1. 대규모 서비스 웹 개발 오리엔테이션
- Ch2. 대규모 데이터 처리 입문

## 의문

## Ch1. 대규모 서비스 웹 개발 오리엔테이션

- 대규모 서비스가 고려해야할 점
  - Reliability
    - no failure, fault tolerant
      - 다중성 확보
        -
  - Scalability(& Loadbalancing)
    - Scale up
      - 너무 비쌈
    - Scale out
      - 서버가 1대일 때에는 고려하지 않을 문제가 생김
        - 로드 밸런싱
        - 데이터 동기화
        - 네트워크 통신 latency
  - Maintainability
    - 서버 모니터링이 필요
      - 최대한 사람이 할 일을 없애기
  - 개발팀 관리
    - 개발 표준화
      - 프로그래밍 언어 통일
      - 라이브러리나 프레임워크 통일
      - 코딩 규약 표준화
      - 버전 관리 시스템 도입
    - 개발 표준화와 같은 것들이 잘 지켜지고 있는지 모니터링
- 대규모 데이터량에 대한 대처
  - 데이터의 계층
    - 하드 디스크 -> 메모리 -> 캐시 메모리 -> CPU
  - 하드 디스크는 느리다
    - 메모리나 캐시 메모리와 비교하면 10^6 ~ 10^9 배나 되는 속도차가 남
    - 디스크의 데이터를 메모리에 캐싱해둠
      - 데이터량이 많아지면, 캐시미스(데이터가 캐시에 존재하지 않는 경우)가 많아짐
  - 본질적 과제
    - 어떻게 하면 데이터를 적게 가져갈 수 있을까
    - 여러 서버로 분산시킬 수 있을까
    - 필요한 데이터를 최소한의 횟수로 읽어들일 수 있을까
- 시스템의 성장전략
  - bad
    - 너무 이른 최적화는 좋지 않다
    - 아무 생각이 없어도 안된다
      - 데이터 규모에 따른 I/O 부하 상승은 순조로운 증가가 아니다
  - good
    - 어느 정도의 수용능력 관리나, 서비스 설계시에 필요 이상으로 데이터를 증가시키지 않도록 하는 설계를 포함시키는게 좋음

## Ch2. 대규모 데이터 처리 입문

- 대규모는 어느정도인가?
  - 하테나 DB
    - entry 테이블
      - 1520만
      - 3GB
    - bookmark 테이블
      - 4500만
      - 5.5GB
    - tag 테이블
      - 5000만
      - 4.7GB
  - DB 쿼리
    - 테이블에서 인덱스를 사용하지 않은 쿼리로 검색하면, 200초가 걸림
      - `SELECT url FROM entry use index(hoge) WHERE eid = 9615899;`
- 대규모 데이터 처리의 어려운 점
  - 대규모 데이터는 어떤 점이 어려운가
    - 메모리 내에서 계산할 수 없다
      - 데이터를 디스크에 두고 검색을 해야 함
      - 디스크는 느리므로 I/O에 시간이 걸림
      - 어떻게 대처할 것인가?
- 메모리와 디스크의 속도차
  - 데이터 탐색
    - 개요
      - 디스크의 특정 원반에 있는 데이터를 찾는 것과, 메모리 내의 특정 번지에 있는데이터 찾는데에 드는 시간 차이
        - 10^5 ~ 10^6배
        - 10만 ~ 100만배
    - c.f) HDD vs SSD
      - 연속 읽기/쓰기
        - 3.5배 SSD가 빠름
      - 랜덤 읽기/쓰기
        - 10 ~ 60배 SSD가 빠름
  - 데이터 전송(버스)
    - 개요
      - 찾은 데이터를 디스크에서 메모리로 보내거나, 메모리에서 CPU로 보내는 등 컴퓨터 내부에서 전송하기 위한 속도
    - 비교
      - 메모리
        - 7.5GB/s
      - 디스크
        - 58MB/s
    - 결과
      - 100배정도 차이가 남
- 단일 호스트의 성능 끌어내기
  - 부하분산 이전에, 단일 서버 성능을 충분히 끌어내기
  - 추측하지 말라, 계측하라
    - 병목 규명작업의 기본적 흐름
      - Load Average(시스템 전체의 부하상황을 나타내는 지표) 확인
        - htop, uptime등의 명령어로 확인
        - (Load Average가 낮은데 시스템 전송량이 오르지 않을 경우)
          - 소프트웨어 설정이나 오류, 네트워크, 원격 호스트측에 원인이 있는지 확인
      - (Load Average가 높은 경우) CPU, I/O중 병목 원인 조사
        - 범인이 CPU인지 I/O인지 확인
          - sar, vmstat
        - CPU부하가 높을 경우
          - 절차
            - 사용자 프로그램의 처리가 병목인지, 시스템 프로그램이 원인인지 확인
              - top, sar
            - 프로세스의 상태나 CPU의 사용시간을 보면서 원인이 되고 있는 프로세스 찾기
              - ps
            - 프로세스를 찾은 후, 보다 상세하게 조사할 경우는 strace로 추적하거나 oprofile로 프로파일링해서 병목지점을 좁혀나감
          - 원인
            - 디스크나 메모리 용량 등 그 밖의 부분에서는 병목이 되지 않는 상태
            - 프로그램이 폭주해서 CPU에 필요이상의 부하가 걸리는 경우
        - I/O부하가 높을 경우
          - 절차
            - 특정 프로세스가 극단적으로 메모리를 소비하고 있지 않은지 파악
              - ps
            - 프로그램의 오류로 메모리를 지나치게 사용하고 있는 경우에 프로그램 개선
            - 탑재된 메모리가 부족한 경우, 증설. 증설이 힘들면 분산
          - 원인
            - 프로그램으로부터 입출력이 많아서 부하가 높음
            - 스왑이 발생해서 디스크 액세스가 발생하는 상황
          - 규명 사항
            - 메모리를 증설해서 캐시 영역을 확보함으로써 대응할 수 있는가
            - 원래 데이터량이 너무 많지 않은가
            - 애플리케이션 측의 I/O 알고리즘을 변경할 필요가 있는가
        - c.f) OS튜닝
          - 병목이 발견되면 이를 제거하는 작업
            - 원래 병목이 없었다면 거기서 더 성능향상을 꾀할 수 없음
