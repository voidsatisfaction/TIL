# 웹 개발자를 위한 대규모 서비스를 지탱하는 기술

- 의문
- Ch1. 대규모 서비스 웹 개발 오리엔테이션
- Ch2. 대규모 데이터 처리 입문
- Ch3. 캐시와 분산
  - OS의 캐시 구조
  - sar 명령으로 OS가 보고하는 각종 지표 참조하기
  - I/O 부하를 줄이는 방법
  - 참고) DB와 페이지 캐시
  - 국소성을 살리는 분산

## 의문

## Ch1. 대규모 서비스 웹 개발 오리엔테이션

- 대규모 서비스가 고려해야할 점
  - Reliability
    - no failure, fault tolerant
      - 다중성 확보
  - Scalability(& Loadbalancing)
    - Scale up
      - 너무 비쌈
    - Scale out
      - 서버가 1대일 때에는 고려하지 않을 문제가 생김
        - 로드 밸런싱
        - 데이터 동기화
        - 네트워크 통신 latency
  - Maintainability
    - 서버 모니터링이 필요
      - 최대한 사람이 할 일을 없애기
  - 개발팀 관리
    - 개발 표준화
      - 프로그래밍 언어 통일
      - 라이브러리나 프레임워크 통일
      - 코딩 규약 표준화
      - 버전 관리 시스템 도입
    - 개발 표준화와 같은 것들이 잘 지켜지고 있는지 모니터링
- 대규모 데이터량에 대한 대처
  - 데이터의 계층
    - 하드 디스크 -> 메모리 -> 캐시 메모리 -> CPU
  - 하드 디스크는 느리다
    - 메모리나 캐시 메모리와 비교하면 10^6 ~ 10^9 배나 되는 속도차가 남
    - 디스크의 데이터를 메모리에 캐싱해둠
      - 데이터량이 많아지면, 캐시미스(데이터가 캐시에 존재하지 않는 경우)가 많아짐
  - 본질적 과제
    - 어떻게 하면 데이터를 적게 가져갈 수 있을까
    - 여러 서버로 분산시킬 수 있을까
    - 필요한 데이터를 최소한의 횟수로 읽어들일 수 있을까
- 시스템의 성장전략
  - bad
    - 너무 이른 최적화는 좋지 않다
    - 아무 생각이 없어도 안된다
      - 데이터 규모에 따른 I/O 부하 상승은 순조로운 증가가 아니다
  - good
    - 어느 정도의 수용능력 관리나, 서비스 설계시에 필요 이상으로 데이터를 증가시키지 않도록 하는 설계를 포함시키는게 좋음

## Ch2. 대규모 데이터 처리 입문

과부하로 인한 시스템 성능의 병목: CPU or I/O

- 대규모는 어느정도인가?
  - 하테나 DB
    - entry 테이블
      - 1520만
      - 3GB
    - bookmark 테이블
      - 4500만
      - 5.5GB
    - tag 테이블
      - 5000만
      - 4.7GB
  - DB 쿼리
    - 테이블에서 인덱스를 사용하지 않은 쿼리로 검색하면, 200초가 걸림
      - `SELECT url FROM entry use index(hoge) WHERE eid = 9615899;`
- 대규모 데이터 처리의 어려운 점
  - 대규모 데이터는 어떤 점이 어려운가
    - 메모리 내에서 계산할 수 없다
      - 데이터를 디스크에 두고 검색을 해야 함
      - 디스크는 느리므로 I/O에 시간이 걸림
      - 어떻게 대처할 것인가?
- 메모리와 디스크의 속도차
  - 데이터 탐색
    - 개요
      - 디스크의 특정 원반에 있는 데이터를 찾는 것과, 메모리 내의 특정 번지에 있는데이터 찾는데에 드는 시간 차이
        - 10^5 ~ 10^6배
        - 10만 ~ 100만배
    - c.f) HDD vs SSD
      - 연속 읽기/쓰기
        - 3.5배 SSD가 빠름
      - 랜덤 읽기/쓰기
        - 10 ~ 60배 SSD가 빠름
  - 데이터 전송(버스)
    - 개요
      - 찾은 데이터를 디스크에서 메모리로 보내거나, 메모리에서 CPU로 보내는 등 컴퓨터 내부에서 전송하기 위한 속도
    - 비교
      - 메모리
        - 7.5GB/s
      - 디스크
        - 58MB/s
    - 결과
      - 100배정도 차이가 남
- 단일 호스트의 성능 끌어내기
  - 부하분산 이전에, 단일 서버 성능을 충분히 끌어내기
  - 추측하지 말라, 계측하라
    - 병목 규명작업의 기본적 흐름
      - Load Average(시스템 전체의 부하상황을 나타내는 지표) 확인
        - htop, uptime등의 명령어로 확인
        - (Load Average가 낮은데 시스템 전송량이 오르지 않을 경우)
          - 소프트웨어 설정이나 오류, 네트워크, 원격 호스트측에 원인이 있는지 확인
      - (Load Average가 높은 경우) CPU, I/O중 병목 원인 조사
        - 범인이 CPU인지 I/O인지 확인
          - sar, vmstat
        - CPU부하가 높을 경우
          - 절차
            - 사용자 프로그램의 처리가 병목인지, 시스템 프로그램이 원인인지 확인
              - top, sar
            - 프로세스의 상태나 CPU의 사용시간을 보면서 원인이 되고 있는 프로세스 찾기
              - ps
            - 프로세스를 찾은 후, 보다 상세하게 조사할 경우는 strace로 추적하거나 oprofile로 프로파일링해서 병목지점을 좁혀나감
          - 원인
            - 디스크나 메모리 용량 등 그 밖의 부분에서는 병목이 되지 않는 상태
            - 프로그램이 폭주해서 CPU에 필요이상의 부하가 걸리는 경우
        - I/O부하가 높을 경우
          - 절차
            - 특정 프로세스가 극단적으로 메모리를 소비하고 있지 않은지 파악
              - ps
            - 프로그램의 오류로 메모리를 지나치게 사용하고 있는 경우에 프로그램 개선
            - 탑재된 메모리가 부족한 경우, 증설. 증설이 힘들면 분산
          - 원인
            - 프로그램으로부터 입출력이 많아서 부하가 높음
            - 스왑이 발생해서 디스크 액세스가 발생하는 상황
          - 규명 사항
            - 메모리를 증설해서 캐시 영역을 확보함으로써 대응할 수 있는가
            - 원래 데이터량이 너무 많지 않은가
            - 애플리케이션 측의 I/O 알고리즘을 변경할 필요가 있는가
        - c.f) OS튜닝
          - 병목이 발견되면 이를 제거하는 작업
            - 원래 병목이 없었다면 거기서 더 성능향상을 꾀할 수 없음
- Scaling
  - 종류
    - scale up
      - 고가의 빠른 하드웨어를 사서 성능을 높이는 것
    - scale out
      - 저가이면서 일반적인 성능의 하드웨어를 많이 나열해서 시스템 전체 성능을 높임
  - 웹 애플리케이션과 부하의 관계
    - 프록시 <-> API 서버 <-> DB 서버
      - 프록시 <-> API 서버
        - CPU 부하
        - I/O 부하
          - 거의 없음(케이스 바이 케이스)
      - API 서버 <-> DB 서버
        - I/O 부하
          - disk
        - Master - Slave 동기화 문제
  - Scaling 대상
    - CPU
      - 비교적 간단함
        - 같은 구성의 서버를 늘리고 로드밸런서로 분산
        - 웹, API 서버, 크롤러
    - I/O
      - 비교적 어려움
        - DB
        - 대규모 데이터
- 대규모 데이터를 다루기 위한 기초 지식
  - 대규모 데이터의 특징
    - 메모리에서 처리하기 어려움
    - 디스크는 느림
  - 대규모 데이터를 다루기 위한 관점
    - 프로그램을 작성할 때
      - 어떻게 하면 메모리에서 처리를 마칠 수 있을까?
        - 디스크 I/O 최소화
        - 국소성을 활용한 분산 실현
      - 데이터량 증가에 강한 알고리즘 사용
        - e.g) 선형탐색 대신 이분탐색
      - 데이터 압축, 정보검색기술
        - 디스크 I/O 최소화
        - 메모리 캐싱이 쉬워짐
    - 프로그램 개발의 한층 아래 기초
      - OS 캐시
      - 분산을 고려한 RDBMS 운용
      - 알고리즘과 데이터 구조
  - c.f) 하테나의 API서버 대수와 DB서버의 대수
    - API서버: 10대
    - DB서버: 25대

## Ch3. 캐시와 분산

대규모 데이터를 다룰 때의 포인트

I/O 대책에 대한 기반은 OS에 있다

- 시나리오
  - OS가 캐시를 통해 대규모 데이터를 효율적으로 처리
  - OS캐시로 제대로 처리할 수 없게 되었을 때 분산에 대해 고려

### OS의 캐시 구조

- 메모리, 디스크, OS 캐시 구조
  - 디스크와 메모리 간 속도차는 10만배 ~ 100만배 이상
  - 메모리를 이용해서 디스크 액세스를 줄임
    - OS는 캐시 구조를 갖춤
- OS 캐시
  - 종류
    - 페이지 캐시
    - 버퍼 캐시
- 가상 메모리
  - 정의
    - 논리적인 선형 메모리 어드레스를 물리적인 물리 메모리 어드레스로 매핑하는 것
  - 특징
    - OS가 커널 내에서 메모리를 추상화
    - 페이지는 OS가 물리 메모리를 확보/관리하는 단위(4KB)
- Linux의 페이지(디스크) 캐시 원리
  - 과정
    - 1 프로세스가 디스크로부터 4KB 크기의 블록을 읽음
    - 2 해당 블록은 메모리상에 위치시켜야 함
      - 프로세스는 디스크에 직접 액세스 불가
    - 3 읽어낸 블록을 메모리에 씀
    - 4 OS는 그 메모리 주소를 프로세스에 논리적 주소로 알려줌
    - 5 프로세스가 해당 메모리에 액세스
    - 6 데이터 읽기가 마쳐도 메모리 블록을 해제하지 않고 남겨둠
    - 7 다른 프로세스가 같은 디스크에 접근할 때, 남겨둔 페이지 재사용
      - 페이지 캐시
  - 특징
    - 디스크의 데이터를 읽으면, 한 번은 메모리에서 데이터가 캐싱됨
      - 두번째 이후 메모리 엑세스가 빨라짐
      - *그래서 재부팅을 하지 않는게 더 빠름?*
    - 디스크 캐시는 VFS가 담당
      - VFS는 파일시스템 구현의 추상화, 페이지 캐시 부분 담당
    - 메모리가 전부 점유 되어있는 경우에는 LRU캐시 로직에 따라 가장 오래전에 읽은 메모리를 파기
    - 리눅스는 메모리가 비어있으면 전부 캐싱
      - 프로세스에서 메모리를 요청했을 때, 캐시로 인해 더 이상 메모리가 남아있지 않으면 오래된 캐시를 버리고 프로세스에 확보
      - 디스크에 데이터가 수 GB정도만 존재하면, 메모리를 8GB 정도 쌓아두면 전부 캐시에 올라감
  - 원리
    - 파일의 inode번호 + 파일의 위치 오프셋으로 캐싱
  - 활용
    - 메모리를 늘리면 페이지 캐시가 늘어나므로 I/O wait의 시간을 크게 단축할 수 있음

#### sar 명령으로 OS가 보고하는 각종 지표 참조하기

- sar(system activity report)
  - 개요
    - OS가 보고하는 각종 지표를 참조
  - 원리
    - sadc라는 백그라운드 프로그램이 커널로부터 리포트를 수집해서 저장
  - 커맨드
    - `sar 1 3`
      - 현재 데이터를 1초 간격으로 3회 봄
    - `sar -f /var/log/sa/sa04 | head`
    - `sar -u`
      - CPU 사용률 확인
      - 필드 설명
        - user
          - 사용자 모드에서 CPU가 소비된 시간의 비율
        - nice
          - nice로 스케쥴링의 우선도를 변경한 프로세스가 사용자 모드에서 CPU를 소비한 시간의 비율
        - system
          - 시스템 모드에서 CPU가 소비된 시간의 비율
        - **iowait**
          - CPU가 디스크 I/O 대기를 위해 Idle 상태로 소비한 시간의 비율
            - *그런데 CPU는 비동기적으로 디스크 I/O 처리를 하지 않는가? 왜 소비해?*
            - 여기서 말하는 iowait은 CPU의 상태가 idle인 경우에, pending I/O requests가 있는 경우에 계상되는 지표
              - 만약, pending I/O requests가 없으면, idle카운트가 올라감
        - steal
          - Xen등 OS의 가상화를 이용하고 있을 경우, 다른 가상 CPU의 계산으로 대기된 시간의 비율
        - idle
          - CPU가 디스크 I/O 대기 등으로 대기되지 않고, Idle 상태로 소비한 시간의 비율
    - `sar -q`
      - Load Average를 확인
      - 필드 설명
        - 실행큐에 쌓여 있는 프로세스의 수
        - 시스템상의 프로세스 사이즈
        - Load Average
    - `sar -r`
      - 메모리 사용 현황 확인
      - 필드 설명
        - kbmemfree
        - kbmemused
        - %memused
        - kbbuffers
        - kbcached
          - 커널 내에서 캐시용 메모리로 사용되고 있는 물리 메모리의 용량
        - kbswpfree
          - 스왑 영역의 남은 용량
        - kbswpused
          - 사용 중인 스왑의 용량
    - `sar -W`
      - 스왑 발생상황 확인
      - 필드 설명
        - pswpin/s
          - 1초 동안에 스왑인이 되고 있는 페이지 수
        - pswpout/s
          - 1초 동안에 스왑아웃이 되고 있는 페이지 수

### I/O 부하를 줄이는 방법

- 기본 자세
  - 캐시를 전제로 I/O를 줄이기 위한 대책을 세워가는 것이 유효
  - 포인트
    - 데이터 규모에 비해 물리 메모리가 크면 전부 캐싱 가능
      - 데이터 크기에 주목
    - 데이터 압축
      - 결국 캐싱
    - 경제적인 비용과 밸런스 고려
      - DB 서버의 경우 메모리를 늘리면 이득이 큼
      - API 서버의 경우 메모리를 늘리는 것이 이득이 크지 않을 수 있음
- 복수 서버로 확장시키기
  - 개요
    - 데이터를 전부 캐싱할 수 없는 규모일 경우
  - 특징
    - API 서버를 늘리는 것과 DB서버를 늘리는 것은 전혀 다른 이야기
    - CPU 부하 분산의 경우
      - API 서버를 단순히 늘린다
    - I/O 분산의 경우
      - 국소성을 고려함
      - 단순히 대수만 늘려서는 확장성을 확보할 수 없다
        - 캐시 용량이 부족해서 늘린다 해도, 캐시가 부족한 부분의 비율도 동일하게 늘려감
          - 병목
- I/O 부하 줄이기와 페이지 캐시
  - 개요
    - Linux는 가능한 한 남아있는 메모리를 페이지 캐시로 활용하려고 함
      - 디스크로 부터 데이터를 읽음
      - 그것이 페이지 캐시에 없고 메모리가 남아있음
        - 남아있지 않으면, 오래된 캐시를 버리고 새로운 캐시로 교체
      - 새로운 캐시 생성
    - c.f) 프로세스가 메모리를 필요로 할 경우에는, 페이지 캐시보다도 우선적으로 메모리 할당
    - 예시
      - DB서버가 저장 하는 데이터의 양이 20GB가 있고, 서버 메모리를 8GB에서 16GB로 증설한 경우, 효과는 어마어마함
        - 20%가 넘는 iowait이 거의 사라
  - 메모리를 증설할 수 없는 경우
    - 데이터를 분할해서 각각의 서버에 위치시키는 것을 검토
      - 데이터를 적절하게 분할하면, 서버 대수를 늘린 만큼 I/O 횟수만 줄어드는 게 아니라, 캐시에 올릴 데이터의 비율이 늘어나므로 상당한 전송량 향상을 기대할 수 있음
  - 페이지 캐시는 한번의 read에서 시작된다
    - 서버를 재부팅한 경우, 페이지 캐시가 전부 초기화 되고, 요청이 많은 DB서버를 캐시가 구축되지 않은 상태로 가동시킴
      - => 모든 DB액세스는 디스크 I/O를 발생시킴
      - => 대규모의 환경에서는 이때문에 DB가 Lock에 걸려 서비스 불능상태가 되기도 함
        - *그렇다고 Lock에 걸려서 서비스가 불능이 되기까지도 하는가?*
      - => 필요한 데이터 전체를 한 번 읽어들인 후에 프러덕션 환경으로 되돌리는 것도 필요함
        - 페이지 캐시 활용

### 참고) DB와 페이지 캐시

MySQL InnoDB buffer pool

![](./images/mysql_innodb_buffer_pool1.png)

- SQLite
  - https://www.sqlite.org/fileio.html#tocentry_132
  - 개요
    - SQLite 데이터베이스 파일의 내용물은 고정된 사이즈의 페이지의 집합으로 포맷이 되어있음
    - SQLite에 의해서 데이터베이스에 행해지는 읽기 쓰기 연산은 페이지 크기의 바이트 블록 단위로 이루어짐
    - 하나의 프로세스에서 동작하는 모든 SQLite DB 커넥션은 하나의 페이지 캐시를 공유함
      - *그런데 각 데이터베이스 커넥션마다 캐싱한다는 글도 있는데 뭐가 맞는거임?*
    - 읽기 연산
      - 페이지 캐시는 페이지 단위로 메모리에 데이터베이스 파일로부터 데이터를 캐싱함
        - 쿼리 수행전에 맞는 버전의 캐시부터 확인
    - 쓰기 연산
      - 데이터 베이스 파일을 구성하는 데이터베이스 페이지를 수정할 경우, 캐시부터 확인
      - 캐시가 있는경우, 페이지 캐시에 있는 캐시 버전을 수정함(dirty page)
      - dirty page를 VFS를 이용하여 database file로 복사
        - 페이지 캐시는 같은 페이지를 두번 업데이트 하는 경우, 데이터베이스 파일에 직접 작성하는 횟수를 줄여줌
- MySQL
  - https://dev.mysql.com/doc/refman/8.0/en/innodb-buffer-pool.html
  - Buffer pool
    - 개요
      - InnoDB가 테이블과 인덱스 데이터가 접근할 때 캐싱하는 메모리 속의 영역
      - 자주 접근하는 데이터를 메모리에서 직접 접근가능하게 해서, 성능향상
      - DB서버에서는 80%의 물리적 메모리가 buffer pool로 사용되기도 함
    - 특징
      - buffer pool은 페이지로 분리되어있고, 각 페이지는 다수의 행을 갖음
      - buffer pool은 페이지의 연결 리스트로 구현되어있음
        - LRU cache
      - DB 튜닝에 중요한 요소
      - WHERE 절이 없는 SELECT문에 대해 수행되는 테이블 스캔은 많은 데이터를 버퍼 풀로 가져옴
        - 가져온 데이터는 new sublist와 old sublist 사이에 삽입

### 국소성을 살리는 분산

- 국소성을 고려한 분산
  - 개요
    - 데이터로 액세스하는 경향에 대한 처리방식에 따라 특정한 방향으로 치우치는 경우
    - 본질은, disk I/O를 최대한 줄이고 데이터를 메모리에서 처리하기 위함
  - 예시
    - DB 서버 1에 A 액세스 패턴이 많고, DB 서버 2에 B액세스 패턴이 많을 경우
  - 방식
    - 1 파티셔닝
      - 테이블 단위 분할
        - 각 테이블 별 각기 다른 서버에서 관리
      - 테이블 데이터 분할
        - 특정 테이블 하나를 여러 개의 작은 테이블로 분할
        - e.g)
          - User테이블을 앞글자에 따라서 분할
    - 2 요청 패턴을 '섬'으로 분할
      - 개요
        - HTTP 요청의 User-Agent나 URL을 보고, 일반적인 사람이면 섬1, 일부 API요청이면 섬3, 봇들에 의한 접근이면 섬2와 같은 식으로 나누는 방법을 사용
          - 사람과 봇의 액세스 패턴이 다름
          - 외부 API를 제공하는 경우 액세스 패턴이 다름
- 페이지 캐시를 고려한 운용의 기본 규칙
