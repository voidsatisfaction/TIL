# 웹 개발자를 위한 대규모 서비스를 지탱하는 기술

- 의문
- Ch1. 대규모 서비스 웹 개발 오리엔테이션
- Ch2. 대규모 데이터 처리 입문

## 의문

## Ch1. 대규모 서비스 웹 개발 오리엔테이션

- 대규모 서비스가 고려해야할 점
  - Reliability
    - no failure, fault tolerant
      - 다중성 확보
        -
  - Scalability(& Loadbalancing)
    - Scale up
      - 너무 비쌈
    - Scale out
      - 서버가 1대일 때에는 고려하지 않을 문제가 생김
        - 로드 밸런싱
        - 데이터 동기화
        - 네트워크 통신 latency
  - Maintainability
    - 서버 모니터링이 필요
      - 최대한 사람이 할 일을 없애기
  - 개발팀 관리
    - 개발 표준화
      - 프로그래밍 언어 통일
      - 라이브러리나 프레임워크 통일
      - 코딩 규약 표준화
      - 버전 관리 시스템 도입
    - 개발 표준화와 같은 것들이 잘 지켜지고 있는지 모니터링
- 대규모 데이터량에 대한 대처
  - 데이터의 계층
    - 하드 디스크 -> 메모리 -> 캐시 메모리 -> CPU
  - 하드 디스크는 느리다
    - 메모리나 캐시 메모리와 비교하면 10^6 ~ 10^9 배나 되는 속도차가 남
    - 디스크의 데이터를 메모리에 캐싱해둠
      - 데이터량이 많아지면, 캐시미스(데이터가 캐시에 존재하지 않는 경우)가 많아짐
  - 본질적 과제
    - 어떻게 하면 데이터를 적게 가져갈 수 있을까
    - 여러 서버로 분산시킬 수 있을까
    - 필요한 데이터를 최소한의 횟수로 읽어들일 수 있을까
- 시스템의 성장전략
  - bad
    - 너무 이른 최적화는 좋지 않다
    - 아무 생각이 없어도 안된다
      - 데이터 규모에 따른 I/O 부하 상승은 순조로운 증가가 아니다
  - good
    - 어느 정도의 수용능력 관리나, 서비스 설계시에 필요 이상으로 데이터를 증가시키지 않도록 하는 설계를 포함시키는게 좋음

## Ch2. 대규모 데이터 처리 입문

과부하로 인한 시스템 성능의 병목: CPU or I/O

- 대규모는 어느정도인가?
  - 하테나 DB
    - entry 테이블
      - 1520만
      - 3GB
    - bookmark 테이블
      - 4500만
      - 5.5GB
    - tag 테이블
      - 5000만
      - 4.7GB
  - DB 쿼리
    - 테이블에서 인덱스를 사용하지 않은 쿼리로 검색하면, 200초가 걸림
      - `SELECT url FROM entry use index(hoge) WHERE eid = 9615899;`
- 대규모 데이터 처리의 어려운 점
  - 대규모 데이터는 어떤 점이 어려운가
    - 메모리 내에서 계산할 수 없다
      - 데이터를 디스크에 두고 검색을 해야 함
      - 디스크는 느리므로 I/O에 시간이 걸림
      - 어떻게 대처할 것인가?
- 메모리와 디스크의 속도차
  - 데이터 탐색
    - 개요
      - 디스크의 특정 원반에 있는 데이터를 찾는 것과, 메모리 내의 특정 번지에 있는데이터 찾는데에 드는 시간 차이
        - 10^5 ~ 10^6배
        - 10만 ~ 100만배
    - c.f) HDD vs SSD
      - 연속 읽기/쓰기
        - 3.5배 SSD가 빠름
      - 랜덤 읽기/쓰기
        - 10 ~ 60배 SSD가 빠름
  - 데이터 전송(버스)
    - 개요
      - 찾은 데이터를 디스크에서 메모리로 보내거나, 메모리에서 CPU로 보내는 등 컴퓨터 내부에서 전송하기 위한 속도
    - 비교
      - 메모리
        - 7.5GB/s
      - 디스크
        - 58MB/s
    - 결과
      - 100배정도 차이가 남
- 단일 호스트의 성능 끌어내기
  - 부하분산 이전에, 단일 서버 성능을 충분히 끌어내기
  - 추측하지 말라, 계측하라
    - 병목 규명작업의 기본적 흐름
      - Load Average(시스템 전체의 부하상황을 나타내는 지표) 확인
        - htop, uptime등의 명령어로 확인
        - (Load Average가 낮은데 시스템 전송량이 오르지 않을 경우)
          - 소프트웨어 설정이나 오류, 네트워크, 원격 호스트측에 원인이 있는지 확인
      - (Load Average가 높은 경우) CPU, I/O중 병목 원인 조사
        - 범인이 CPU인지 I/O인지 확인
          - sar, vmstat
        - CPU부하가 높을 경우
          - 절차
            - 사용자 프로그램의 처리가 병목인지, 시스템 프로그램이 원인인지 확인
              - top, sar
            - 프로세스의 상태나 CPU의 사용시간을 보면서 원인이 되고 있는 프로세스 찾기
              - ps
            - 프로세스를 찾은 후, 보다 상세하게 조사할 경우는 strace로 추적하거나 oprofile로 프로파일링해서 병목지점을 좁혀나감
          - 원인
            - 디스크나 메모리 용량 등 그 밖의 부분에서는 병목이 되지 않는 상태
            - 프로그램이 폭주해서 CPU에 필요이상의 부하가 걸리는 경우
        - I/O부하가 높을 경우
          - 절차
            - 특정 프로세스가 극단적으로 메모리를 소비하고 있지 않은지 파악
              - ps
            - 프로그램의 오류로 메모리를 지나치게 사용하고 있는 경우에 프로그램 개선
            - 탑재된 메모리가 부족한 경우, 증설. 증설이 힘들면 분산
          - 원인
            - 프로그램으로부터 입출력이 많아서 부하가 높음
            - 스왑이 발생해서 디스크 액세스가 발생하는 상황
          - 규명 사항
            - 메모리를 증설해서 캐시 영역을 확보함으로써 대응할 수 있는가
            - 원래 데이터량이 너무 많지 않은가
            - 애플리케이션 측의 I/O 알고리즘을 변경할 필요가 있는가
        - c.f) OS튜닝
          - 병목이 발견되면 이를 제거하는 작업
            - 원래 병목이 없었다면 거기서 더 성능향상을 꾀할 수 없음
- Scaling
  - 종류
    - scale up
      - 고가의 빠른 하드웨어를 사서 성능을 높이는 것
    - scale out
      - 저가이면서 일반적인 성능의 하드웨어를 많이 나열해서 시스템 전체 성능을 높임
  - 웹 애플리케이션과 부하의 관계
    - 프록시 <-> API 서버 <-> DB 서버
      - 프록시 <-> API 서버
        - CPU 부하
        - I/O 부하
          - 거의 없음(케이스 바이 케이스)
      - API 서버 <-> DB 서버
        - I/O 부하
          - disk
        - Master - Slave 동기화 문제
  - Scaling 대상
    - CPU
      - 비교적 간단함
        - 같은 구성의 서버를 늘리고 로드밸런서로 분산
        - 웹, API 서버, 크롤러
    - I/O
      - 비교적 어려움
        - DB
        - 대규모 데이터
- 대규모 데이터를 다루기 위한 기초 지식
  - 대규모 데이터의 특징
    - 메모리에서 처리하기 어려움
    - 디스크는 느림
  - 대규모 데이터를 다루기 위한 관점
    - 프로그램을 작성할 때
      - 어떻게 하면 메모리에서 처리를 마칠 수 있을까?
        - 디스크 I/O 최소화
        - 국소성을 활용한 분산 실현
      - 데이터량 증가에 강한 알고리즘 사용
        - e.g) 선형탐색 대신 이분탐색
      - 데이터 압축, 정보검색기술
        - 디스크 I/O 최소화
        - 메모리 캐싱이 쉬워짐
    - 프로그램 개발의 한층 아래 기초
      - OS 캐시
      - 분산을 고려한 RDBMS 운용
      - 알고리즘과 데이터 구조
  - c.f) 하테나의 API서버 대수와 DB서버의 대수
    - API서버: 10대
    - DB서버: 25대

## Ch3. 캐시와 분산

대규모 데이터를 다룰 때의 포인트

I/O 대책에 대한 기반은 OS에 있다

- 시나리오
  - OS가 캐시를 통해 대규모 데이터를 효율적으로 처리
  - OS캐시로 제대로 처리할 수 없게 되었을 때 분산에 대해 고려

### OS의 캐시 구조

- 메모리, 디스크, OS 캐시 구조
  - 디스크와 메모리 간 속도차는 10만배 ~ 100만배 이상
  - 메모리를 이용해서 디스크 액세스를 줄임
    - OS는 캐시 구조를 갖춤
- OS 캐시
  - 종류
    - 페이지 캐시
    - 버퍼 캐시
- 가상 메모리
  - 정의
    - 논리적인 선형 메모리 어드레스를 물리적인 물리 메모리 어드레스로 매핑하는 것
  - 특징
    - OS가 커널 내에서 메모리를 추상화
    - 페이지는 OS가 물리 메모리를 확보/관리하는 단위(4KB)
- Linux의 페이지(디스크) 캐시 원리
  - 과정
    - 1 프로세스가 디스크로부터 4KB 크기의 블록을 읽음
    - 2 해당 블록은 메모리상에 위치시켜야 함
      - 프로세스는 디스크에 직접 액세스 불가
    - 3 읽어낸 블록을 메모리에 씀
    - 4 OS는 그 메모리 주소를 프로세스에 논리적 주소로 알려줌
    - 5 프로세스가 해당 메모리에 액세스
    - 6 데이터 읽기가 마쳐도 메모리 블록을 해제하지 않고 남겨둠
    - 7 다른 프로세스가 같은 디스크에 접근할 때, 남겨둔 페이지 재사용
      - 페이지 캐시
  - 특징
    - 디스크의 데이터를 읽으면, 한 번은 메모리에서 데이터가 캐싱됨
      - 두번째 이후 메모리 엑세스가 빨라짐
      - *그래서 재부팅을 하지 않는게 더 빠름?*
    - 디스크 캐시는 VFS가 담당
      - VFS는 파일시스템 구현의 추상화, 페이지 캐시 부분 담당
    - 메모리가 전부 점유 되어있는 경우에는 LRU캐시 로직에 따라 가장 오래전에 읽은 메모리를 파기
    - 리눅스는 메모리가 비어있으면 전부 캐싱
      - 프로세스에서 메모리를 요청했을 때, 캐시로 인해 더 이상 메모리가 남아있지 않으면 오래된 캐시를 버리고 프로세스에 확보
      - 디스크에 데이터가 수 GB정도만 존재하면, 메모리를 8GB 정도 쌓아두면 전부 캐시에 올라감
  - 원리
    - 파일의 inode번호 + 파일의 위치 오프셋으로 캐싱
  - 활용
    - 메모리를 늘리면 페이지 캐시가 늘어나므로 I/O wait의 시간을 크게 단축할 수 있음

### sar 명령으로 OS가 보고하는 각종 지표 참조하기

- sar(system activity report)
  - 개요
    - OS가 보고하는 각종 지표를 참조
  - 원리
    - sadc라는 백그라운드 프로그램이 커널로부터 리포트를 수집해서 저장
  - 커맨드
    - `sar 1 3`
      - 현재 데이터를 1초 간격으로 3회 봄
    - `sar -f /var/log/sa/sa04 | head`
    - `sar -u`
      - CPU 사용률 확인
      - 필드 설명
        - user
          - 사용자 모드에서 CPU가 소비된 시간의 비율
        - nice
          - nice로 스케쥴링의 우선도를 변경한 프로세스가 사용자 모드에서 CPU를 소비한 시간의 비율
        - system
          - 시스템 모드에서 CPU가 소비된 시간의 비율
        - **iowait**
          - CPU가 디스크 I/O 대기를 위해 Idle 상태로 소비한 시간의 비율
            - *그런데 CPU는 비동기적으로 디스크 I/O 처리를 하지 않는가? 왜 소비해?*
        - steal
          - Xen등 OS의 가상화를 이용하고 있을 경우, 다른 가상 CPU의 계산으로 대기된 시간의 비율
        - idle
          - CPU가 디스크 I/O 대기 등으로 대기되지 않고, Idle 상태로 소비한 시간의 비율
    - `sar -q`
      - Load Average를 확인
      - 필드 설명
        - 실행큐에 쌓여 있는 프로세스의 수
        - 시스템상의 프로세스 사이즈
        - Load Average
    - `sar -r`
      - 메모리 사용 현황 확인
      - 필드 설명
        - kbmemfree
        - kbmemused
        - %memused
        - kbbuffers
        - kbcached
          - 커널 내에서 캐시용 메모리로 사용되고 있는 물리 메모리의 용량
        - kbswpfree
          - 스왑 영역의 남은 용량
        - kbswpused
          - 사용 중인 스왑의 용량
